<div align="center">
    
 <div>
    <a href="https://github.com/yipoh/AesExpert"><img src="https://img.shields.io/github/stars/yipoh/AesExpert"/></a>
    <a href="https://arxiv.org/abs/2404.09624"><img src="https://img.shields.io/badge/Arxiv-2404:09624-red"/></a>
    <a href="https://pan.baidu.com/s/15vRoUcXBZodVWwkvfEJa9Q?pwd=h9vn"><img src="https://img.shields.io/badge/BaiduYun%20-Model%20Release-blue"></a>

   </div>

 <h1>AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception </h1>

  <div>
      <a href="https://github.com/yipoh" target="_blank">Yipo Huang</a><sup>1</sup>,
      <a href="https://github.com/yipoh/AesBench" target="_blank">Xiangfei Sheng</a><sup>1</sup>,
      <a href="https://github.com/zc-cpu" target="_blank">Zhichao Yang</a><sup>1</sup>,
      <a href="https://github.com/dylanqyuan" target="_blank">Quan Yuan</a><sup>1</sup>,
      <a href="https://github.com/yipoh/AesBench" target="_blank">Zhichao Duan</a><sup>1</sup>,
  </div>

   <div>
      <a href="https://faculty.xidian.edu.cn/chenpengfei/en/index.htm" target="_blank">Pengfei Chen</a><sup>1</sup>,
      <a href="https://scholar.google.com/citations?user=xMvuFI8AAAAJ&hl=en&oi=ao" target="_blank">Leida Li</a><sup>1</sup><sup>#</sup>,
      <a href="https://scholar.google.com/citations?user=D_S41X4AAAAJ&hl=en&oi=ao" target="_blank">Weisi Lin</a><sup>2</sup>,
      <a href="https://scholar.google.com/citations?hl=zh-CN&user=11aRt9oAAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Guangming Shi</a><sup>1</sup>,
  </div>


  <div>
  <sup>1</sup>Xidian University, <sup>2</sup>Nanyang Technological University
       </div>   

<div>
<sup>#</sup>Corresponding author
   </div>


<h5 align="center"> If you like this work, please give us a star ‚≠ê on GitHub.  </h2>




</div>

 <br>

</h5>
</p> 
<p align="center">
    <img src="figs/teaserFig.png"/>
<p>
    <p align="center">Performance of the proposed AesExpert on various aesthetic perception dimensions, in comparison with the most advanced GPT-4V and Gemini-Pro-Vision, as well as the open-sourced LLaVA-1.5-13B.</p>
    </p> 
     </p> 
     </p> 

## News
- [2024/04/16] üö© Data is coming soon...

